{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d84a504",
   "metadata": {},
   "source": [
    "## Fake Data Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa2fbd",
   "metadata": {},
   "source": [
    "### About The Data\n",
    "This dataset contains 18K job descriptions out of which about 800 are fake. The data consists of both textual information and meta-information about the jobs. The dataset can be used to create classification models which can learn the job descriptions which are fraudulent. A small proportion of these descriptions are fake or scam which can be identified by the column \"fraudulent\". \n",
    "\n",
    "The data is provide by the University of the Aegean | Laboratory of Information & Communication Systems Security\n",
    "\n",
    "http://emscad.samos.aegean.gr/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb063a9",
   "metadata": {},
   "source": [
    "## Dictonary:\n",
    "-  job_id: Unique ID (int64)\n",
    "-  title: Title of job description (str)\n",
    "-  location: Geographical location of the job ad (Example: US, NY, New York)\n",
    "-  department: Corporate department (e.g. Marketing, Success, Sales, ANDROIDPIT, ...)\n",
    "-  salary_range: Indicative salary range (e.g. 50,000-60,000 ($))\n",
    "-  company_profile: A brief company description.\n",
    "-  description: The details description of the job ad.\n",
    "-  requirements: Enlisted requirements for the job opening.\n",
    "-  benefits: Enlisted offered benefits by the employer.\n",
    "-  telecommuting: True for telecommuting positions. --> remote or not\n",
    "-  has_company_logo: True if company logo is present.\n",
    "-  has_questions: True if screening questions are present.\n",
    "-  employment_type: Type of emplyment (e.g. Full-type, Part-time, Contract, etc.)\n",
    "-  required_experience: Required Experience (e.g. Executive, Entry level, Intern, etc.)\n",
    "-  required_education: Required Education (e.g. Doctorate, Master’s Degree, Bachelor, etc)\n",
    "-  industry: Industry (e.g. Automotive, IT, Health care, Real estate, etc.)\n",
    "-  function: Position as function in the company (e.g. Consulting, Engineering, Research, Sales etc.)\n",
    "-  fraudulent: Classifcation target (0, 1)\n",
    "\n",
    "\n",
    "# Columns to do:\n",
    "## string manipulation\n",
    "- title\n",
    "- company_profile\n",
    "- description\n",
    "- requirements\n",
    "- benefits\n",
    "\n",
    "## one-hot encode\n",
    "- location (3.105) - cities and countries --> remove\n",
    "    - countries = 90 (346 is NA) --> keep\n",
    "- industry (groups = 131) --> boolean mask (group all with less than 30 into one group) --> create category with missings\n",
    "- function (groups = 37)  --> create category with missings\n",
    "\n",
    "- employment_type (groups = 5) \n",
    "- required_experience (groups = 7)\n",
    "- required_education (groups = 13)\n",
    "\n",
    "## binary (no mising)\n",
    "- telecommuting\n",
    "- has_company_logo\n",
    "- has_questions\n",
    "- salary_range --> turn into binary (has salary range or not)\n",
    "- department (groups = 1337) --> binary \n",
    "\n",
    "## target\n",
    "- fraudulent (binary)\n",
    "\n",
    "## dropping\n",
    "department (groups = 1337) --> boolean mask (group all with less than 30 into one group) --> drop for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277ea0f",
   "metadata": {},
   "source": [
    "# Questions\n",
    "- How to impute data with more sophisticated methods?\n",
    "- How to examine whether values are true NAs or just the result of company size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b85c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c665554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "data_path = '/home/lars/code/syeda-tabassum-rahaman/scam-job-detector/raw_data/fake_job_postings.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33d7e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department\n",
       "0    11547\n",
       "1     6333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['department'].map(lambda x: 0 if pd.isna(x) else 1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f729ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean raw data by\n",
    "    - Creating new features for columns with missing values above >30% as binary features: missing = 0, not missing = 1\n",
    "    - Cleaning text data by removing stopwords, digits, lamatizing, etc.\n",
    "    - \n",
    "    \"\"\"\n",
    "    def preprocessing(sentence):\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        # remove punctuation\n",
    "        for punctuation in string.punctuation:\n",
    "            sentence = sentence.replace(punctuation, '')\n",
    "\n",
    "        # set to lowercase\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        # remove numbers\n",
    "        for char in string.digits:\n",
    "            sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "\n",
    "        # tokenize\n",
    "        tokens = word_tokenize(sentence)\n",
    "\n",
    "        # removing stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # lemmatize\n",
    "        tokens = [WordNetLemmatizer().lemmatize(word, pos='v') for word in tokens]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    # path = Path('.')\n",
    "    df = pd.read_csv('../raw_data/fake_job_postings.csv')\n",
    "    print('dataset loaded')\n",
    "\n",
    "    # Creating binary columns for missing values:\n",
    "    df['department_binary'] = df['department'].map(lambda x: 0 if pd.isna(x) else 1)\n",
    "    \n",
    "    df['salary_range_binary'] = df['salary_range'].map(lambda x: 0 if pd.isna(x) else 1)\n",
    "    \n",
    "    # Clean text data\n",
    "    cols = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna('missing value')\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = df[col].apply(preprocessing)\n",
    "    \n",
    "    # extracting country ID\n",
    "    df['country'] = df['location'].astype(str).apply(lambda x: x.split(',')[0])\n",
    "\n",
    "    # dropping columns\n",
    "    df.drop(columns=['salary_range', 'department', 'location', 'job_id'], inplace=True)\n",
    "    \n",
    "\n",
    "    print(\"✅ data cleaned\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13aa402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n",
      "✅ data cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>department_binary</th>\n",
       "      <th>salary_range_binary</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>market intern</td>\n",
       "      <td>food weve create groundbreaking awardwinning c...</td>\n",
       "      <td>food fastgrowing jam beard awardwinning online...</td>\n",
       "      <td>experience content management systems major pl...</td>\n",
       "      <td>miss value</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer service cloud video production</td>\n",
       "      <td>second worlds cloud video production service s...</td>\n",
       "      <td>organise focus vibrant awesomedo passion custo...</td>\n",
       "      <td>expect youyour key responsibility communicate ...</td>\n",
       "      <td>get usthrough part second team gainexperience ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commission machinery assistant cma</td>\n",
       "      <td>valor service provide workforce solutions meet...</td>\n",
       "      <td>client locate houston actively seek experience...</td>\n",
       "      <td>implement precommissioning commission procedur...</td>\n",
       "      <td>miss value</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>account executive washington dc</td>\n",
       "      <td>passion improve quality life geography heart e...</td>\n",
       "      <td>company esri – environmental systems research ...</td>\n",
       "      <td>education bachelor ’ master ’ gi business admi...</td>\n",
       "      <td>culture anything corporate—we collaborative cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill review manager</td>\n",
       "      <td>spotsource solutions llc global human capital ...</td>\n",
       "      <td>job title itemization review managerlocation f...</td>\n",
       "      <td>qualificationsrn license state texasdiploma ba...</td>\n",
       "      <td>full benefit offer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Hospital &amp; Health Care</td>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>account director distribution</td>\n",
       "      <td>vend look awesome new talent come join us youl...</td>\n",
       "      <td>case first time ’ visit website vend award win...</td>\n",
       "      <td>ace role youwill eat comprehensive statements ...</td>\n",
       "      <td>expect uswe open culture openly share result i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>payroll accountant</td>\n",
       "      <td>weblinc ecommerce platform service provider fa...</td>\n",
       "      <td>payroll accountant focus primarily payroll fun...</td>\n",
       "      <td>ba bs account desire fun love genuine passion ...</td>\n",
       "      <td>health amp wellnessmedical planprescription dr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Accounting/Auditing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>project cost control staff engineer cost contr...</td>\n",
       "      <td>provide full time permanent position many medi...</td>\n",
       "      <td>experience project cost control staff engineer...</td>\n",
       "      <td>least years professional experienceability wor...</td>\n",
       "      <td>miss value</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>graphic designer</td>\n",
       "      <td>miss value</td>\n",
       "      <td>nemsia studios look experience visualgraphic d...</td>\n",
       "      <td>must fluent latest versions corel amp adobe cc...</td>\n",
       "      <td>competitive salary compensation base experienc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Graphic Design</td>\n",
       "      <td>Design</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>web application developers</td>\n",
       "      <td>vend look awesome new talent come join us youl...</td>\n",
       "      <td>wevend award win web base point sale software ...</td>\n",
       "      <td>want hear ifyou indepth understand oo programm...</td>\n",
       "      <td>miss value</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                          market intern   \n",
       "1                customer service cloud video production   \n",
       "2                     commission machinery assistant cma   \n",
       "3                        account executive washington dc   \n",
       "4                                    bill review manager   \n",
       "...                                                  ...   \n",
       "17875                      account director distribution   \n",
       "17876                                 payroll accountant   \n",
       "17877  project cost control staff engineer cost contr...   \n",
       "17878                                   graphic designer   \n",
       "17879                         web application developers   \n",
       "\n",
       "                                         company_profile  \\\n",
       "0      food weve create groundbreaking awardwinning c...   \n",
       "1      second worlds cloud video production service s...   \n",
       "2      valor service provide workforce solutions meet...   \n",
       "3      passion improve quality life geography heart e...   \n",
       "4      spotsource solutions llc global human capital ...   \n",
       "...                                                  ...   \n",
       "17875  vend look awesome new talent come join us youl...   \n",
       "17876  weblinc ecommerce platform service provider fa...   \n",
       "17877  provide full time permanent position many medi...   \n",
       "17878                                         miss value   \n",
       "17879  vend look awesome new talent come join us youl...   \n",
       "\n",
       "                                             description  \\\n",
       "0      food fastgrowing jam beard awardwinning online...   \n",
       "1      organise focus vibrant awesomedo passion custo...   \n",
       "2      client locate houston actively seek experience...   \n",
       "3      company esri – environmental systems research ...   \n",
       "4      job title itemization review managerlocation f...   \n",
       "...                                                  ...   \n",
       "17875  case first time ’ visit website vend award win...   \n",
       "17876  payroll accountant focus primarily payroll fun...   \n",
       "17877  experience project cost control staff engineer...   \n",
       "17878  nemsia studios look experience visualgraphic d...   \n",
       "17879  wevend award win web base point sale software ...   \n",
       "\n",
       "                                            requirements  \\\n",
       "0      experience content management systems major pl...   \n",
       "1      expect youyour key responsibility communicate ...   \n",
       "2      implement precommissioning commission procedur...   \n",
       "3      education bachelor ’ master ’ gi business admi...   \n",
       "4      qualificationsrn license state texasdiploma ba...   \n",
       "...                                                  ...   \n",
       "17875  ace role youwill eat comprehensive statements ...   \n",
       "17876  ba bs account desire fun love genuine passion ...   \n",
       "17877  least years professional experienceability wor...   \n",
       "17878  must fluent latest versions corel amp adobe cc...   \n",
       "17879  want hear ifyou indepth understand oo programm...   \n",
       "\n",
       "                                                benefits  telecommuting  \\\n",
       "0                                             miss value              0   \n",
       "1      get usthrough part second team gainexperience ...              0   \n",
       "2                                             miss value              0   \n",
       "3      culture anything corporate—we collaborative cr...              0   \n",
       "4                                     full benefit offer              0   \n",
       "...                                                  ...            ...   \n",
       "17875  expect uswe open culture openly share result i...              0   \n",
       "17876  health amp wellnessmedical planprescription dr...              0   \n",
       "17877                                         miss value              0   \n",
       "17878  competitive salary compensation base experienc...              0   \n",
       "17879                                         miss value              0   \n",
       "\n",
       "       has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                     1              0           Other          Internship   \n",
       "1                     1              0       Full-time      Not Applicable   \n",
       "2                     1              0             NaN                 NaN   \n",
       "3                     1              0       Full-time    Mid-Senior level   \n",
       "4                     1              1       Full-time    Mid-Senior level   \n",
       "...                 ...            ...             ...                 ...   \n",
       "17875                 1              1       Full-time    Mid-Senior level   \n",
       "17876                 1              1       Full-time    Mid-Senior level   \n",
       "17877                 0              0       Full-time                 NaN   \n",
       "17878                 0              1        Contract      Not Applicable   \n",
       "17879                 1              1       Full-time    Mid-Senior level   \n",
       "\n",
       "      required_education                   industry              function  \\\n",
       "0                    NaN                        NaN             Marketing   \n",
       "1                    NaN  Marketing and Advertising      Customer Service   \n",
       "2                    NaN                        NaN                   NaN   \n",
       "3      Bachelor's Degree          Computer Software                 Sales   \n",
       "4      Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
       "...                  ...                        ...                   ...   \n",
       "17875                NaN          Computer Software                 Sales   \n",
       "17876  Bachelor's Degree                   Internet   Accounting/Auditing   \n",
       "17877                NaN                        NaN                   NaN   \n",
       "17878       Professional             Graphic Design                Design   \n",
       "17879                NaN          Computer Software           Engineering   \n",
       "\n",
       "       fraudulent  department_binary  salary_range_binary country  \n",
       "0               0                  1                    0      US  \n",
       "1               0                  1                    0      NZ  \n",
       "2               0                  0                    0      US  \n",
       "3               0                  1                    0      US  \n",
       "4               0                  0                    0      US  \n",
       "...           ...                ...                  ...     ...  \n",
       "17875           0                  1                    0      CA  \n",
       "17876           0                  1                    0      US  \n",
       "17877           0                  0                    0      US  \n",
       "17878           0                  0                    0      NG  \n",
       "17879           0                  1                    0      NZ  \n",
       "\n",
       "[17880 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_test = clean_data(df)\n",
    "\n",
    "d_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743e51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# catagorical columns for One-Hot Encoding\n",
    "categorical_columns = [\n",
    "    'country',\n",
    "    'industry',\n",
    "    'function',\n",
    "    'employment_type'\n",
    "]\n",
    "# ordinal columns for Ordinal Encoding\n",
    "ordinal_columns = [\n",
    "    'required_experience',\n",
    "    'required_education'\n",
    "]\n",
    "#binary columns for binary encoding\n",
    "binary_columns = ['has_company_logo', 'has_questions', 'department_binary', 'salary_range_binary']\n",
    "\n",
    "#text columns for TF-IDF Vectorizer\n",
    "text_columns = [\n",
    "        'title',\n",
    "        'company_profile',\n",
    "        'description',\n",
    "        'requirements',\n",
    "        'benefits'\n",
    "]\n",
    "\n",
    "#reference lists for ordinal encoding\n",
    "experience_order = [\n",
    "    \"Not Applicable\",\n",
    "    \"Unknown\",\n",
    "    \"Internship\",\n",
    "    \"Entry level\",\n",
    "    \"Associate\",\n",
    "    \"Mid-Senior level\",\n",
    "    \"Director\",\n",
    "    \"Executive\"\n",
    "]\n",
    "\n",
    "education_order = [\n",
    "    \"Unknown\",\n",
    "    \"High School or equivalent\",\n",
    "    \"Vocational\",\n",
    "    \"Certification\",\n",
    "    \"Some College Coursework Completed\",\n",
    "    \"Associate Degree\",\n",
    "    \"Bachelor's Degree\",\n",
    "    \"Professional\",\n",
    "    \"Master's Degree\"\n",
    "]\n",
    "\n",
    "\n",
    "# preprocessor pipeline\n",
    "def preprocessing_pipeline() -> ColumnTransformer:\n",
    "\n",
    "    cat_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "        OneHotEncoder(handle_unknown='ignore')\n",
    "    )\n",
    "    ordinal_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "        OrdinalEncoder(\n",
    "        categories=[experience_order, education_order],\n",
    "        handle_unknown=\"use_encoded_value\",\n",
    "        unknown_value=-1)\n",
    "    )\n",
    "    binary_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy='most_frequent', fill_value=0),\n",
    "        OneHotEncoder(handle_unknown='ignore')\n",
    "    )\n",
    "\n",
    "    def combine_text(X):\n",
    "        return X[text_columns].fillna(\"\").agg(\" \".join, axis=1)\n",
    "    \n",
    "    text_transformer = make_pipeline(\n",
    "        FunctionTransformer(combine_text, validate=False),\n",
    "        TfidfVectorizer(max_features=5000)\n",
    "    )\n",
    "\n",
    "    \n",
    "    preprocessor = make_column_transformer(\n",
    "        (cat_transformer, categorical_columns),\n",
    "        (ordinal_transformer, ordinal_columns),\n",
    "        (binary_transformer, binary_columns),\n",
    "        (text_transformer, text_columns)\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "# train preprocessor pipeline\n",
    "def train_preprocessor(X_train: pd.DataFrame, X_test: pd.DataFrame) -> np.ndarray:\n",
    "    preprocessor = preprocessing_pipeline()\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    return X_train_preprocessed, X_test_preprocessed\n",
    "\n",
    "\n",
    "# # test preprocessor pipeline\n",
    "# def test_preprocessor(X: pd.DataFrame) -> np.ndarray:\n",
    "#     preprocessor = preprocessing_pipeline()\n",
    "#     X_preprocessed = preprocessor.transform(X)\n",
    "#     return X_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90ddec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d_test #.drop(columns=['title'])\n",
    "# Extract X and y\n",
    "X = df.drop(columns=['fraudulent'])\n",
    "y = df['fraudulent']\n",
    "# Make train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# preprocess train and test data\n",
    "X_train_preprocessed, X_test_preprocessed = train_preprocessor(X_train, X_test)\n",
    "# X_test_preprocessed = test_preprocessor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce8b3784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 2161764 stored elements and shape (14304, 5273)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60bf0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of LogisticRegression(max_iter=1000)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "result = model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "result.score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "665620d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5606936416184971 0.97 0.9779082774049217\n"
     ]
    }
   ],
   "source": [
    "y_pred = result.predict(X_test_preprocessed)\n",
    "\n",
    "print(recall_score(y_test, y_pred), precision_score(y_test, y_pred), accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02b9f4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary_range</th>\n",
       "      <td>15012</td>\n",
       "      <td>83.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department</th>\n",
       "      <td>11547</td>\n",
       "      <td>64.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required_education</th>\n",
       "      <td>8105</td>\n",
       "      <td>45.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benefits</th>\n",
       "      <td>7212</td>\n",
       "      <td>40.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required_experience</th>\n",
       "      <td>7050</td>\n",
       "      <td>39.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>6455</td>\n",
       "      <td>36.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>4903</td>\n",
       "      <td>27.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_type</th>\n",
       "      <td>3471</td>\n",
       "      <td>19.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_profile</th>\n",
       "      <td>3308</td>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requirements</th>\n",
       "      <td>2696</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>346</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>346</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_company_logo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telecommuting</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_questions</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraudulent</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     missing_count  missing_percent\n",
       "salary_range                 15012            83.96\n",
       "department                   11547            64.58\n",
       "required_education            8105            45.33\n",
       "benefits                      7212            40.34\n",
       "required_experience           7050            39.43\n",
       "function                      6455            36.10\n",
       "industry                      4903            27.42\n",
       "employment_type               3471            19.41\n",
       "company_profile               3308            18.50\n",
       "requirements                  2696            15.08\n",
       "location                       346             1.94\n",
       "country                        346             1.94\n",
       "description                      1             0.01\n",
       "title                            0             0.00\n",
       "job_id                           0             0.00\n",
       "has_company_logo                 0             0.00\n",
       "telecommuting                    0             0.00\n",
       "has_questions                    0             0.00\n",
       "fraudulent                       0             0.00"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = pd.DataFrame({\n",
    "\"missing_count\": df.isna().sum(),\n",
    "\"missing_percent\": (df.isna().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "missing_df.sort_values(\"missing_percent\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'] = df['location'].str[:2]\n",
    "df['country'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af01a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "df['location'].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1feae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (17880, 18)\n",
      "Size: 321840\n",
      "Unique Ids: 17880\n",
      "Locations: 3105\n",
      "Departments: 1337; ['Marketing' 'Success' nan ... 'Admin - Clerical' 'Administrative Dept'\n",
      " 'Hospitality']\n",
      "Salary Range: count     2868\n",
      "unique     874\n",
      "top        0-0\n",
      "freq       142\n",
      "Name: salary_range, dtype: object\n",
      "Column names: Index(['job_id', 'title', 'location', 'department', 'salary_range',\n",
      "       'company_profile', 'description', 'requirements', 'benefits',\n",
      "       'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
      "       'required_experience', 'required_education', 'industry', 'function',\n",
      "       'fraudulent'],\n",
      "      dtype='object')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Shape: {df.shape}\n",
    "Size: {df.size}\n",
    "Unique Ids: {df.job_id.nunique()}\n",
    "Locations: {df.location.nunique()}\n",
    "Departments: {df.department.nunique()}; {df.department.unique()}\n",
    "Salary Range: {df.salary_range.describe()}\n",
    "Column names: {df.columns}\n",
    "\n",
    "'''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a06cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocessing(sentence):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "\n",
    "    # set to lowercase\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # remove numbers\n",
    "    for char in string.digits:\n",
    "        sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # removing stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # lemmatize\n",
    "    tokens = [WordNetLemmatizer().lemmatize(word, pos='v') for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3af4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating unique values for missing text data\n",
    "# cols = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "# Clean reviews\n",
    "cols = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "\n",
    "df_t = df.copy()\n",
    "\n",
    "for col in cols:\n",
    "    df_t[col] = df_t[col].fillna('missing value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a83dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean reviews\n",
    "for col in cols:\n",
    "    df_t[col] = df_t[col].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import set_config; set_config(\"diagram\")\n",
    "\n",
    "# Create Pipeline\n",
    "pipe = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "# Set parameters to search\n",
    "X = df['clean_reviews']\n",
    "y = df['target_encoded']\n",
    "\n",
    "params = {\n",
    "    'tfidfvectorizer__ngram_range': ((1,1), (2,2)),\n",
    "    'multinomialnb__alpha': (0.1,1)\n",
    "}\n",
    "\n",
    "# Perform grid search on pipeline\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator = pipe,\n",
    "#     param_grid = params,\n",
    "#     scoring = \"recall\",\n",
    "#     cv = 5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6a59c",
   "metadata": {},
   "source": [
    "# Thoughts\n",
    "\n",
    "- For the basic ML Pipeline, we vectorize each of the descriptions seperately, add these vectors along with metainformation to train the model.\n",
    "- For deep learning, we will create different paths\n",
    "    1. Creating one document per entry by merging all information in a systematic way.\n",
    "    2. Creating a meta-data sentence, and leave all description parts seperated. We will then train one moddel per part. At theend we will train a model taking the probabilities for each part to get to a desion.\n",
    "    3. Same as 2. just that we will train one model taking all parts as inputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scam_job_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
