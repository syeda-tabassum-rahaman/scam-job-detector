{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d84a504",
   "metadata": {},
   "source": [
    "## Fake Data Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa2fbd",
   "metadata": {},
   "source": [
    "### About The Data\n",
    "This dataset contains 18K job descriptions out of which about 800 are fake. The data consists of both textual information and meta-information about the jobs. The dataset can be used to create classification models which can learn the job descriptions which are fraudulent. A small proportion of these descriptions are fake or scam which can be identified by the column \"fraudulent\". \n",
    "\n",
    "The data is provide by the University of the Aegean | Laboratory of Information & Communication Systems Security\n",
    "\n",
    "http://emscad.samos.aegean.gr/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb063a9",
   "metadata": {},
   "source": [
    "## Dictonary:\n",
    "-  job_id: Unique ID (int64)\n",
    "-  title: Title of job description (str)\n",
    "-  location: Geographical location of the job ad (Example: US, NY, New York)\n",
    "-  department: Corporate department (e.g. Marketing, Success, Sales, ANDROIDPIT, ...)\n",
    "-  salary_range: Indicative salary range (e.g. 50,000-60,000 ($))\n",
    "-  company_profile: A brief company description.\n",
    "-  description: The details description of the job ad.\n",
    "-  requirements: Enlisted requirements for the job opening.\n",
    "-  benefits: Enlisted offered benefits by the employer.\n",
    "-  telecommuting: True for telecommuting positions. --> remote or not\n",
    "-  has_company_logo: True if company logo is present.\n",
    "-  has_questions: True if screening questions are present.\n",
    "-  employment_type: Type of emplyment (e.g. Full-type, Part-time, Contract, etc.)\n",
    "-  required_experience: Required Experience (e.g. Executive, Entry level, Intern, etc.)\n",
    "-  required_education: Required Education (e.g. Doctorate, Masterâ€™s Degree, Bachelor, etc)\n",
    "-  industry: Industry (e.g. Automotive, IT, Health care, Real estate, etc.)\n",
    "-  function: Position as function in the company (e.g. Consulting, Engineering, Research, Sales etc.)\n",
    "-  fraudulent: Classifcation target (0, 1)\n",
    "\n",
    "\n",
    "# Columns to do:\n",
    "## string manipulation\n",
    "- title\n",
    "- company_profile\n",
    "- description\n",
    "- requirements\n",
    "- benefits\n",
    "\n",
    "## one-hot encode\n",
    "- location (3.105) - cities and countries --> remove\n",
    "    - countries = 90 (346 is NA) --> keep\n",
    "- industry (groups = 131) --> boolean mask (group all with less than 30 into one group) --> create category with missings\n",
    "- function (groups = 37)  --> create category with missings\n",
    "\n",
    "- employment_type (groups = 5) \n",
    "- required_experience (groups = 7)\n",
    "- required_education (groups = 13)\n",
    "\n",
    "## binary (no mising)\n",
    "- telecommuting\n",
    "- has_company_logo\n",
    "- has_questions\n",
    "- salary_range --> turn into binary (has salary range or not)\n",
    "\n",
    "## target\n",
    "- fraudulent (binary)\n",
    "\n",
    "## dropping\n",
    "department (groups = 1337) --> boolean mask (group all with less than 30 into one group) --> drop for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277ea0f",
   "metadata": {},
   "source": [
    "# Questions\n",
    "- How to impute data with more sophisticated methods?\n",
    "- How to examine whether values are true NAs or just the result of company size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b85c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c665554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "data_path = '/home/lars/code/syeda-tabassum-rahaman/scam-job-detector/raw_data/fake_job_postings.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d7e573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Marketing\n",
       "1            Customer Service\n",
       "2                         NaN\n",
       "3                       Sales\n",
       "4        Health Care Provider\n",
       "                 ...         \n",
       "17875                   Sales\n",
       "17876     Accounting/Auditing\n",
       "17877                     NaN\n",
       "17878                  Design\n",
       "17879             Engineering\n",
       "Name: function, Length: 17880, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02b9f4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary_range</th>\n",
       "      <td>15012</td>\n",
       "      <td>83.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>department</th>\n",
       "      <td>11547</td>\n",
       "      <td>64.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required_education</th>\n",
       "      <td>8105</td>\n",
       "      <td>45.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benefits</th>\n",
       "      <td>7212</td>\n",
       "      <td>40.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required_experience</th>\n",
       "      <td>7050</td>\n",
       "      <td>39.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>function</th>\n",
       "      <td>6455</td>\n",
       "      <td>36.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>4903</td>\n",
       "      <td>27.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_type</th>\n",
       "      <td>3471</td>\n",
       "      <td>19.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_profile</th>\n",
       "      <td>3308</td>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requirements</th>\n",
       "      <td>2696</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>346</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>346</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_company_logo</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telecommuting</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_questions</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraudulent</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     missing_count  missing_percent\n",
       "salary_range                 15012            83.96\n",
       "department                   11547            64.58\n",
       "required_education            8105            45.33\n",
       "benefits                      7212            40.34\n",
       "required_experience           7050            39.43\n",
       "function                      6455            36.10\n",
       "industry                      4903            27.42\n",
       "employment_type               3471            19.41\n",
       "company_profile               3308            18.50\n",
       "requirements                  2696            15.08\n",
       "location                       346             1.94\n",
       "country                        346             1.94\n",
       "description                      1             0.01\n",
       "title                            0             0.00\n",
       "job_id                           0             0.00\n",
       "has_company_logo                 0             0.00\n",
       "telecommuting                    0             0.00\n",
       "has_questions                    0             0.00\n",
       "fraudulent                       0             0.00"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = pd.DataFrame({\n",
    "\"missing_count\": df.isna().sum(),\n",
    "\"missing_percent\": (df.isna().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "missing_df.sort_values(\"missing_percent\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'] = df['location'].str[:2]\n",
    "df['country'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1feae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (17880, 18)\n",
      "Size: 321840\n",
      "Unique Ids: 17880\n",
      "Locations: 3105\n",
      "Departments: 1337; ['Marketing' 'Success' nan ... 'Admin - Clerical' 'Administrative Dept'\n",
      " 'Hospitality']\n",
      "Salary Range: count     2868\n",
      "unique     874\n",
      "top        0-0\n",
      "freq       142\n",
      "Name: salary_range, dtype: object\n",
      "Column names: Index(['job_id', 'title', 'location', 'department', 'salary_range',\n",
      "       'company_profile', 'description', 'requirements', 'benefits',\n",
      "       'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
      "       'required_experience', 'required_education', 'industry', 'function',\n",
      "       'fraudulent'],\n",
      "      dtype='object')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Shape: {df.shape}\n",
    "Size: {df.size}\n",
    "Unique Ids: {df.job_id.nunique()}\n",
    "Locations: {df.location.nunique()}\n",
    "Departments: {df.department.nunique()}; {df.department.unique()}\n",
    "Salary Range: {df.salary_range.describe()}\n",
    "Column names: {df.columns}\n",
    "\n",
    "'''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a06cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocessing(sentence):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "\n",
    "    # set to lowercase\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # remove numbers\n",
    "    for char in string.digits:\n",
    "        sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # removing stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # lemmatize\n",
    "    tokens = [WordNetLemmatizer().lemmatize(word, pos='v') for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3af4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating unique values for missing text data\n",
    "# cols = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "# Clean reviews\n",
    "cols = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "\n",
    "df_t = df.copy()\n",
    "\n",
    "for col in cols:\n",
    "    df_t[col] = df_t[col].fillna('missing value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a83dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean reviews\n",
    "for col in cols:\n",
    "    df_t[col] = df_t[col].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import set_config; set_config(\"diagram\")\n",
    "\n",
    "# Create Pipeline\n",
    "pipe = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "# Set parameters to search\n",
    "X = df['clean_reviews']\n",
    "y = df['target_encoded']\n",
    "\n",
    "params = {\n",
    "    'tfidfvectorizer__ngram_range': ((1,1), (2,2)),\n",
    "    'multinomialnb__alpha': (0.1,1)\n",
    "}\n",
    "\n",
    "# Perform grid search on pipeline\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator = pipe,\n",
    "#     param_grid = params,\n",
    "#     scoring = \"recall\",\n",
    "#     cv = 5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6a59c",
   "metadata": {},
   "source": [
    "# Thoughts\n",
    "\n",
    "- For the basic ML Pipeline, we vectorize each of the descriptions seperately, add these vectors along with metainformation to train the model.\n",
    "- For deep learning, we will create different paths\n",
    "    1. Creating one document per entry by merging all information in a systematic way.\n",
    "    2. Creating a meta-data sentence, and leave all description parts seperated. We will then train one moddel per part. At theend we will train a model taking the probabilities for each part to get to a desion.\n",
    "    3. Same as 2. just that we will train one model taking all parts as inputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scam_job_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
