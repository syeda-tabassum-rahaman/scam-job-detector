{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d84a504",
   "metadata": {},
   "source": [
    "## Fake Data Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa2fbd",
   "metadata": {},
   "source": [
    "### About The Data\n",
    "This dataset contains 18K job descriptions out of which about 800 are fake. The data consists of both textual information and meta-information about the jobs. The dataset can be used to create classification models which can learn the job descriptions which are fraudulent. A small proportion of these descriptions are fake or scam which can be identified by the column \"fraudulent\". \n",
    "\n",
    "The data is provide by the University of the Aegean | Laboratory of Information & Communication Systems Security\n",
    "\n",
    "http://emscad.samos.aegean.gr/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb063a9",
   "metadata": {},
   "source": [
    "## Dictonary:\n",
    "-  job_id: Unique ID (int64)\n",
    "-  title: Title of job description (str)\n",
    "-  location: Geographical location of the job ad (Example: US, NY, New York)\n",
    "-  department: Corporate department (e.g. Marketing, Success, Sales, ANDROIDPIT, ...)\n",
    "-  salary_range: Indicative salary range (e.g. 50,000-60,000 ($))\n",
    "-  company_profile: A brief company description.\n",
    "-  description: The details description of the job ad.\n",
    "-  requirements: Enlisted requirements for the job opening.\n",
    "-  benefits: Enlisted offered benefits by the employer.\n",
    "-  telecommuting: True for telecommuting positions. --> remote or not\n",
    "-  has_company_logo: True if company logo is present.\n",
    "-  has_questions: True if screening questions are present.\n",
    "-  employment_type: Type of emplyment (e.g. Full-type, Part-time, Contract, etc.)\n",
    "-  required_experience: Required Experience (e.g. Executive, Entry level, Intern, etc.)\n",
    "-  required_education: Required Education (e.g. Doctorate, Master‚Äôs Degree, Bachelor, etc)\n",
    "-  industry: Industry (e.g. Automotive, IT, Health care, Real estate, etc.)\n",
    "-  function: Position as function in the company (e.g. Consulting, Engineering, Research, Sales etc.)\n",
    "-  fraudulent: Classifcation target (0, 1)\n",
    "\n",
    "\n",
    "# Columns to do:\n",
    "## string manipulation\n",
    "- title\n",
    "- company_profile\n",
    "- description\n",
    "- requirements\n",
    "- benefits\n",
    "\n",
    "## one-hot encode\n",
    "- location (3.105) - cities and countries --> remove\n",
    "    - countries = 90 (346 is NA) --> keep\n",
    "- industry (groups = 131) --> boolean mask (group all with less than 30 into one group) --> create category with missings\n",
    "- function (groups = 37)  --> create category with missings\n",
    "\n",
    "- employment_type (groups = 5) \n",
    "- required_experience (groups = 7)\n",
    "- required_education (groups = 13)\n",
    "\n",
    "## binary (no mising)\n",
    "- telecommuting\n",
    "- has_company_logo\n",
    "- has_questions\n",
    "- salary_range --> turn into binary (has salary range or not)\n",
    "- department (groups = 1337) --> binary \n",
    "\n",
    "## target\n",
    "- fraudulent (binary)\n",
    "\n",
    "## dropping\n",
    "department (groups = 1337) --> boolean mask (group all with less than 30 into one group) --> drop for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277ea0f",
   "metadata": {},
   "source": [
    "# Questions\n",
    "- How to impute data with more sophisticated methods?\n",
    "- How to examine whether values are true NAs or just the result of company size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b85c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c665554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "data_path = '/home/lars/code/syeda-tabassum-rahaman/scam-job-detector/raw_data/fake_job_postings.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_idx = df[\"industry\"].value_counts().head(10).index\n",
    "df[\"industry\"] = df[\"industry\"].where(df[\"industry\"].isin(top5_idx), \"Other\")\n",
    "\n",
    "\n",
    "# extracting country ID\n",
    "df['country'] = df['location'].astype(str).apply(lambda x: x.split(',')[0])\n",
    "top5_idx = df[\"country\"].value_counts().head(10).index\n",
    "df[\"country\"] = df[\"country\"].where(df[\"country\"].isin(top5_idx), \"Other\")\n",
    "\n",
    "\n",
    "top5_idx = df[\"function\"].value_counts().head(10).index\n",
    "df[\"function\"] = df[\"function\"].where(df[\"function\"].isin(top5_idx), \"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6cf0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text columns for TF-IDF Vectorizer\n",
    "text_columns = [\n",
    "        'title',\n",
    "        'company_profile',\n",
    "        'description',\n",
    "        'requirements',\n",
    "        'benefits'\n",
    "]\n",
    "df[text_columns] = df[text_columns].fillna(\"\").astype(str)\n",
    "\n",
    "df[\"job_description\"] = df[text_columns].agg(\" \".join, axis=1).str.strip()\n",
    "# Clean text data\n",
    "df['job_description'] = df['job_description'].fillna('missing value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095dcc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_type\n",
       "Full-time    11620\n",
       "Contract      1524\n",
       "Part-time      797\n",
       "Temporary      241\n",
       "Other          227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts = df[\"employment_type\"].value_counts()\n",
    "# small = counts[counts < 100].index\n",
    "\n",
    "df[\"employment_type_grp\"] = df[\"employment_type\"].where(~df[\"employment_type\"].isin(\"Contract\"), \"Other\")\n",
    "df[\"employment_type_grp\"].value_counts().nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd14541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (17880, 18)\n",
      "Size: 321840\n",
      "Unique Ids: 17880\n",
      "Locations: 3105\n",
      "Departments: 1337; ['Marketing' 'Success' nan ... 'Admin - Clerical' 'Administrative Dept'\n",
      " 'Hospitality']\n",
      "Salary Range: count     2868\n",
      "unique     874\n",
      "top        0-0\n",
      "freq       142\n",
      "Name: salary_range, dtype: object\n",
      "Column names: Index(['job_id', 'title', 'location', 'department', 'salary_range',\n",
      "       'company_profile', 'description', 'requirements', 'benefits',\n",
      "       'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
      "       'required_experience', 'required_education', 'industry', 'function',\n",
      "       'fraudulent'],\n",
      "      dtype='object')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Shape: {df.shape}\n",
    "Size: {df.size}\n",
    "Unique Ids: {df.job_id.nunique()}\n",
    "Locations: {df.location.nunique()}\n",
    "Departments: {df.department.nunique()}; {df.department.unique()}\n",
    "Salary Range: {df.salary_range.describe()}\n",
    "Column names: {df.columns}\n",
    "\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "767db68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'Full-time', nan, 'Part-time', 'Contract', 'Temporary'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.employment_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e90da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry = df.industry.unique().tolist()\n",
    "\n",
    "\n",
    "import json\n",
    "with open(\"/home/lars/code/Lars-Koenig-Git/scam_job_detector/data/industry.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(industry, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "991526b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_type = df.employment_type.unique().tolist()\n",
    "\n",
    "\n",
    "import json\n",
    "with open(\"/home/lars/code/Lars-Koenig-Git/scam_job_detector/data/employment_type.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(employment_type, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e730a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marketing',\n",
       " 'Customer Service',\n",
       " 'Other',\n",
       " 'Sales',\n",
       " 'Health Care Provider',\n",
       " 'Information Technology',\n",
       " 'Engineering',\n",
       " 'Administrative',\n",
       " 'Design',\n",
       " 'Education']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function = df.function.unique().tolist()\n",
    "function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc83b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "with open(\"/home/lars/code/Lars-Koenig-Git/scam_job_detector/data/function.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(function, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f729ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean raw data by\n",
    "    - Creating new features for columns with missing values above >30% as binary features: missing = 0, not missing = 1\n",
    "    - Cleaning text data by removing stopwords, digits, lamatizing, etc.\n",
    "    - \n",
    "    \"\"\"\n",
    "    def preprocessing(sentence):\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        # remove punctuation\n",
    "        for punctuation in string.punctuation:\n",
    "            sentence = sentence.replace(punctuation, '')\n",
    "\n",
    "        # set to lowercase\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        # remove numbers\n",
    "        for char in string.digits:\n",
    "            sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "\n",
    "        # tokenize\n",
    "        tokens = word_tokenize(sentence)\n",
    "\n",
    "        # removing stop words\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # lemmatize\n",
    "        tokens = [WordNetLemmatizer().lemmatize(word, pos='v') for word in tokens]\n",
    "\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    # path = Path('.')\n",
    "    df = pd.read_csv('../raw_data/fake_job_postings.csv')\n",
    "    print('dataset loaded')\n",
    "\n",
    "    # Creating binary columns for missing values:\n",
    "    df['department_binary'] = df['department'].map(lambda x: 0 if pd.isna(x) else 1)\n",
    "    \n",
    "    df['salary_range_binary'] = df['salary_range'].map(lambda x: 0 if pd.isna(x) else 1)\n",
    "    \n",
    "    # Clean text data\n",
    "    cols = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna('missing value')\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = df[col].apply(preprocessing)\n",
    "    \n",
    "    # extracting country ID\n",
    "    df['country'] = df['location'].astype(str).apply(lambda x: x.split(',')[0])\n",
    "\n",
    "    # dropping columns\n",
    "    df.drop(columns=['salary_range', 'department', 'location', 'job_id'], inplace=True)\n",
    "    \n",
    "\n",
    "    print(\"‚úÖ data cleaned\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "743e51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "# catagorical columns for One-Hot Encoding\n",
    "categorical_columns = [\n",
    "    'country',\n",
    "    'industry',\n",
    "    'function',\n",
    "    'employment_type'\n",
    "]\n",
    "# ordinal columns for Ordinal Encoding\n",
    "ordinal_columns = [\n",
    "    'required_experience',\n",
    "    'required_education'\n",
    "]\n",
    "#binary columns for binary encoding\n",
    "binary_columns = ['has_company_logo', 'has_questions', 'department_binary', 'salary_range_binary']\n",
    "\n",
    "#text columns for TF-IDF Vectorizer\n",
    "text_columns = [\n",
    "        'title',\n",
    "        'company_profile',\n",
    "        'description',\n",
    "        'requirements',\n",
    "        'benefits'\n",
    "]\n",
    "\n",
    "#reference lists for ordinal encoding\n",
    "experience_order = [\n",
    "    \"Not Applicable\",\n",
    "    \"Unknown\",\n",
    "    \"Internship\",\n",
    "    \"Entry level\",\n",
    "    \"Associate\",\n",
    "    \"Mid-Senior level\",\n",
    "    \"Director\",\n",
    "    \"Executive\"\n",
    "]\n",
    "\n",
    "education_order = [\n",
    "    \"Unknown\",\n",
    "    \"High School or equivalent\",\n",
    "    \"Vocational\",\n",
    "    \"Certification\",\n",
    "    \"Some College Coursework Completed\",\n",
    "    \"Associate Degree\",\n",
    "    \"Bachelor's Degree\",\n",
    "    \"Professional\",\n",
    "    \"Master's Degree\"\n",
    "]\n",
    "\n",
    "\n",
    "# preprocessor pipeline\n",
    "def preprocessing_pipeline() -> ColumnTransformer:\n",
    "\n",
    "    cat_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "        OneHotEncoder(handle_unknown='ignore')\n",
    "    )\n",
    "    ordinal_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "        OrdinalEncoder(\n",
    "        categories=[experience_order, education_order],\n",
    "        handle_unknown=\"use_encoded_value\",\n",
    "        unknown_value=-1)\n",
    "    )\n",
    "    binary_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy='most_frequent', fill_value=0),\n",
    "        OneHotEncoder(handle_unknown='ignore')\n",
    "    )\n",
    "\n",
    "    def combine_text(X):\n",
    "        return X[text_columns].fillna(\"\").agg(\" \".join, axis=1)\n",
    "    \n",
    "    text_transformer = make_pipeline(\n",
    "        FunctionTransformer(combine_text, validate=False),\n",
    "        TfidfVectorizer(max_features=5000)\n",
    "    )\n",
    "\n",
    "    \n",
    "    preprocessor = make_column_transformer(\n",
    "        (cat_transformer, categorical_columns),\n",
    "        (ordinal_transformer, ordinal_columns),\n",
    "        (binary_transformer, binary_columns),\n",
    "        (text_transformer, text_columns)\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "# train preprocessor pipeline\n",
    "def train_preprocessor(X_train: pd.DataFrame, X_test: pd.DataFrame) -> np.ndarray:\n",
    "    preprocessor = preprocessing_pipeline()\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    return X_train_preprocessed, X_test_preprocessed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ddec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded\n",
      "‚úÖ data cleaned\n"
     ]
    }
   ],
   "source": [
    "df = clean_data(df)\n",
    "# Extract X and y\n",
    "X = df.drop(columns=['fraudulent'])\n",
    "y = df['fraudulent']\n",
    "# Make train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# preprocess train and test data\n",
    "X_train_preprocessed, X_test_preprocessed = train_preprocessor(X_train, X_test)\n",
    "# X_test_preprocessed = test_preprocessor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b495533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9738533643916376)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = clean_data(df)\n",
    "# Extract X and y\n",
    "X = df.drop(columns=['fraudulent'])\n",
    "y = df['fraudulent']\n",
    "# Make train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# preprocess train and test data\n",
    "X_train_preprocessed, X_test_preprocessed = train_preprocessor(X_train, X_test)\n",
    "# X_test_preprocessed = test_preprocessor(X_test)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    # (\"clean_preproc\", clean_preproc),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "cross_val_score(pipe, X_train_preprocessed, y_train, cv=cv).mean()\n",
    "\n",
    "cross_model = cross_validate(pipe, X_train_preprocessed, y_train, cv=cv)\n",
    "cross_model\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "result = model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "result.score\n",
    "\n",
    "y_pred = result.predict(X_test_preprocessed)\n",
    "\n",
    "print(recall_score(y_test, y_pred), precision_score(y_test, y_pred), accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f82b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.61700773, 0.65386415, 0.56823897, 0.60018778, 0.63627195]),\n",
       " 'score_time': array([0.00219345, 0.00320959, 0.0033884 , 0.00193262, 0.00251102]),\n",
       " 'test_score': array([0.97413492, 0.97553303, 0.97203775, 0.9751835 , 0.97237762])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bf0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ClassifierMixin.score of LogisticRegression(max_iter=1000)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "result = model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "result.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "665620d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5606936416184971 0.97 0.9779082774049217\n"
     ]
    }
   ],
   "source": [
    "y_pred = result.predict(X_test_preprocessed)\n",
    "\n",
    "print(recall_score(y_test, y_pred), precision_score(y_test, y_pred), accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186d011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    recall_score, precision_score, balanced_accuracy_score, f1_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from scam_job_detector.ML_logic.preprocessor import train_preprocessor, test_preprocessor\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# import scam_job_detector.ML_logic.preprocessor as pre\n",
    "# print(\"Imported from:\", pre.__file__)\n",
    "# print(\"Functions available:\", dir(pre))\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad0fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/lars/code/syeda-tabassum-rahaman/scam-job-detector/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a366068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec: /home/lars/code/syeda-tabassum-rahaman/scam-job-detector/scam_job_detector/__init__.py\n",
      "imported from: /home/lars/code/syeda-tabassum-rahaman/scam-job-detector/scam_job_detector/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "\n",
    "# 1) remove already-loaded installed package from this kernel\n",
    "for k in list(sys.modules):\n",
    "    if k == \"scam_job_detector\" or k.startswith(\"scam_job_detector.\"):\n",
    "        del sys.modules[k]\n",
    "\n",
    "# 2) put your repo's src first (src-layout)\n",
    "SRC = \"/home/lars/code/syeda-tabassum-rahaman/scam-job-detector/src\"\n",
    "sys.path.insert(0, SRC)\n",
    "\n",
    "# 3) now check what would be imported\n",
    "spec = importlib.util.find_spec(\"scam_job_detector\")\n",
    "print(\"spec:\", spec.origin)\n",
    "\n",
    "# 4) import and verify\n",
    "import scam_job_detector\n",
    "print(\"imported from:\", scam_job_detector.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6738ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clean data loaded\n",
      "Preprocessor saved at /home/lars/code/syeda-tabassum-rahaman/scam-job-detector/models/preprocessor.dill\n",
      "\n",
      "    Model Performance\n",
      "    Recall: 0.7398843930635838,\n",
      "    Precision: 0.9922480620155039,\n",
      "    Balanced Accuracy: 0.8697952673516567,\n",
      "    F1 Score: 0.847682119205298\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# 'PROJECT_ROOT = Path(\"/home/lars/code/Lars-Koenig-Git/scam_job_detector/\")  # folder that contains your package folder\n",
    "# sys.path.insert(0, str(PROJECT_ROOT'))\n",
    "\n",
    "# Load cleaned dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# usually the folder where you launched jupyter, or where the notebook lives\n",
    "base_path = Path.cwd().resolve().parent\n",
    "clean_data_path = base_path / \"raw_data\" / \"data_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(clean_data_path)\n",
    "print(\"‚úÖ Clean data loaded\")\n",
    "\n",
    "# Train-test split\n",
    "X = df.drop(columns=[\"fraudulent\"])\n",
    "y = df[\"fraudulent\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocess once\n",
    "X_train_pp, preprocessor = train_preprocessor(X_train)\n",
    "X_test_pp = test_preprocessor(X_test)\n",
    "\n",
    "# Paths for saving models\n",
    "models_folder = os.path.join(base_path, \"models\")\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "\n",
    "winner_path = os.path.join(models_folder, \"model_winner.dill\")\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=11,\n",
    "    n_estimators=275\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_pp, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test_pp)\n",
    "\n",
    "print(f'''\n",
    "    Model Performance\n",
    "    Recall: {recall_score(y_test, y_pred)},\n",
    "    Precision: {precision_score(y_test, y_pred)},\n",
    "    Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)},\n",
    "    F1 Score: {f1_score(y_test, y_pred)}\n",
    "    ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a966ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7530     0\n",
       "129      0\n",
       "4640     0\n",
       "402      0\n",
       "13218    0\n",
       "        ..\n",
       "1841     0\n",
       "11852    0\n",
       "10870    0\n",
       "565      0\n",
       "13398    0\n",
       "Name: fraudulent, Length: 14304, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4bca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3872292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    recall_score, precision_score, balanced_accuracy_score, f1_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from scam_job_detector.ML_logic.preprocessor import train_preprocessor, test_preprocessor\n",
    "\n",
    "def initialize_all_grid_searches(run_logreg=True, run_xgb=True):\n",
    "    \"\"\"\n",
    "    Run grid-searches for baseline models only if requested.\n",
    "    Preprocess data only once.\n",
    "    Save best estimators for each model.\n",
    "    Finally compute the best model (\"winner model\") based on test AP score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load cleaned dataset\n",
    "    base_path = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n",
    "    clean_data_path = os.path.join(base_path, \"raw_data\", \"data_cleaned.csv\")\n",
    "\n",
    "    df = pd.read_csv(clean_data_path)\n",
    "    print(\"‚úÖ Clean data loaded\")\n",
    "\n",
    "    # Train-test split\n",
    "    X = df.drop(columns=[\"fraudulent\"])\n",
    "    y = df[\"fraudulent\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Preprocess once\n",
    "    X_train_pp, preprocessor = train_preprocessor(X_train)\n",
    "    X_test_pp = test_preprocessor(X_test)\n",
    "\n",
    "    # Paths for saving models\n",
    "    models_folder = os.path.join(base_path, \"models\")\n",
    "    os.makedirs(models_folder, exist_ok=True)\n",
    "\n",
    "    logreg_path = os.path.join(models_folder, \"model_logreg.dill\")\n",
    "    xgb_path = os.path.join(models_folder, \"model_xgb.dill\")\n",
    "    winner_path = os.path.join(models_folder, \"model_winner.dill\")\n",
    "\n",
    "    # Store results for winner selection\n",
    "    model_scores = {}\n",
    "\n",
    "    # ====================================================== #\n",
    "    # 1Ô∏è‚É£ LOGISTIC REGRESSION GRID SEARCH (if requested)\n",
    "    # ====================================================== #\n",
    "    if run_logreg:\n",
    "        print(\"\\nüîç Running Logistic Regression Grid Search...\")\n",
    "\n",
    "        param_grid_logreg = {\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "\n",
    "        grid_lr = GridSearchCV(\n",
    "            LogisticRegression(),\n",
    "            param_grid_logreg,\n",
    "            cv=5,\n",
    "            scoring='average_precision',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_lr.fit(X_train_pp, y_train)\n",
    "\n",
    "        best_lr = grid_lr.best_estimator_\n",
    "\n",
    "        with open(logreg_path, \"wb\") as f:\n",
    "            dill.dump(best_lr, f)\n",
    "\n",
    "        # Results\n",
    "        print(\"‚úÖ Grid search for LR completed\")\n",
    "\n",
    "        # Inspect best estimator:\n",
    "        print(f\"Best score: {grid_lr.best_score_}\")\n",
    "        print(f\"Best parameters:, {grid_lr.best_params_}\")\n",
    "        print(f\"Best estimator:, {grid_lr.best_estimator_}\")\n",
    "\n",
    "        # model performance on test set\n",
    "        y_pred = grid_lr.predict(X_test_pp)\n",
    "        print(f'''\n",
    "            Model Performance\n",
    "            Recall: {recall_score(y_test, y_pred)},\n",
    "            Precision: {precision_score(y_test, y_pred)},\n",
    "            Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)},\n",
    "            F1 Score: {f1_score(y_test, y_pred)}\n",
    "            ''')\n",
    "\n",
    "    else:\n",
    "        print(\"\\nüìÇ Loading previously saved Logistic Regression model...\")\n",
    "        if os.path.exists(logreg_path):\n",
    "            with open(logreg_path, \"rb\") as f:\n",
    "                best_lr = dill.load(f)\n",
    "        else:\n",
    "            best_lr = None\n",
    "\n",
    "    # Evaluate LR if available\n",
    "    if best_lr is not None:\n",
    "        y_pred_lr = best_lr.predict(X_test_pp)\n",
    "        ap_lr = average_precision_score(y_test, y_pred_lr)\n",
    "        model_scores[\"logreg\"] = (ap_lr, best_lr)\n",
    "        print(f\"üîé Logistic Regression AP on test: {ap_lr:.4f}\")\n",
    "\n",
    "    # ====================================================== #\n",
    "    # 2Ô∏è‚É£ XGBOOST GRID SEARCH (if requested)\n",
    "    # ====================================================== #\n",
    "    if run_xgb:\n",
    "        print(\"\\nüîç Running XGBoost Grid Search...\")\n",
    "\n",
    "        param_grid_xgb = {\n",
    "\n",
    "            'n_estimators': [275], #[260, 275, 290]\n",
    "            'max_depth': [11], # [11, 12, 13]\n",
    "            'learning_rate': [0.1],\n",
    "\n",
    "        }\n",
    "        xgb = XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        grid_xgb = GridSearchCV(\n",
    "            xgb,\n",
    "            param_grid_xgb,\n",
    "            cv=5,\n",
    "            scoring='average_precision',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        grid_xgb.fit(X_train_pp, y_train)\n",
    "\n",
    "        best_xgb = grid_xgb.best_estimator_\n",
    "\n",
    "        with open(xgb_path, \"wb\") as f:\n",
    "            dill.dump(best_xgb, f)\n",
    "\n",
    "        print(f\"‚úÖ Saved XGBoost model at {xgb_path}\")\n",
    "                # Results\n",
    "        print(\"‚úÖ Grid search for XGboost completed\")\n",
    "\n",
    "        # Inspect best estimator:\n",
    "        print(f\"Best score: {grid_xgb.best_score_}\")\n",
    "        print(f\"Best parameters:, {grid_xgb.best_params_}\")\n",
    "        print(f\"Best estimator:, {grid_xgb.best_estimator_}\")\n",
    "\n",
    "        # model performance on test set\n",
    "        y_pred = best_xgb.predict(X_test_pp)\n",
    "        print(f'''\n",
    "            Model Performance\n",
    "            Recall: {recall_score(y_test, y_pred)},\n",
    "            Precision: {precision_score(y_test, y_pred)},\n",
    "            Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred)},\n",
    "            F1 Score: {f1_score(y_test, y_pred)}\n",
    "            ''')\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"\\nüìÇ Loading previously saved XGBoost model...\")\n",
    "        if os.path.exists(xgb_path):\n",
    "            with open(xgb_path, \"rb\") as f:\n",
    "                best_xgb = dill.load(f)\n",
    "        else:\n",
    "            best_xgb = None\n",
    "\n",
    "    # Evaluate XGB if available\n",
    "    if best_xgb is not None:\n",
    "        y_pred_xgb = best_xgb.predict(X_test_pp)\n",
    "        y_pred_xgb_proba = best_xgb.predict_proba(X_test_pp)[:, 1]\n",
    "        ap_xgb = average_precision_score(y_test, y_pred_xgb_proba)\n",
    "        model_scores[\"xgb\"] = (ap_xgb, best_xgb)\n",
    "        print(f\"üîé XGBoost AP on test: {ap_xgb:.4f}\")\n",
    "\n",
    "    # ====================================================== #\n",
    "    # 3Ô∏è‚É£ CHOOSE THE WINNER MODEL\n",
    "    # ====================================================== #\n",
    "    if len(model_scores) == 0:\n",
    "        print(\"‚ùå No models available for comparison. Nothing to save.\")\n",
    "        return None\n",
    "\n",
    "    winner_name = max(model_scores, key=lambda k: model_scores[k][0])\n",
    "    winner_score, winner_model = model_scores[winner_name]\n",
    "\n",
    "    with open(winner_path, \"wb\") as f:\n",
    "        dill.dump(winner_model, f)\n",
    "\n",
    "    print(f\"\\nüèÜ WINNER MODEL: {winner_name}  (AP={winner_score:.4f})\")\n",
    "    print(f\"üíæ Saved at {winner_path}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6a59c",
   "metadata": {},
   "source": [
    "# Thoughts\n",
    "\n",
    "- For the basic ML Pipeline, we vectorize each of the descriptions seperately, add these vectors along with metainformation to train the model.\n",
    "- For deep learning, we will create different paths\n",
    "    1. Creating one document per entry by merging all information in a systematic way.\n",
    "    2. Creating a meta-data sentence, and leave all description parts seperated. We will then train one moddel per part. At theend we will train a model taking the probabilities for each part to get to a desion.\n",
    "    3. Same as 2. just that we will train one model taking all parts as inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8dcee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79d3aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"‚ùå Error: Key not found. Check your .env path and file content.\")\n",
    "else:\n",
    "    print(\"‚úÖ Key loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfc9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1836ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = SystemMessage(\n",
    "    \"\"\"You are screening job offers for three variables:\n",
    "\n",
    "    1. Country: Insert one of the following: \"Missing\": \"Not listed in job offer\",  \"Other\": \"Not included in list\",  \"US\": \"United States of America\",  \"NZ\": \"New Zealand\",  \"DE\": \"Germany\",  \"GB\": \"United Kingdom\",  \"AU\": \"Australia\",  \"CA\": \"Canada\",  \"IN\": \"India\",  \"GR\": \"Greece\",  \"PH\": \"Philippines\"\n",
    "    2. Industry: \"Missing\",   \"Other\",  \"Marketing and Advertising\",  \"Computer Software\",  \"Hospital & Health Care\",  \"Information Technology and Services\",  \"Financial Services\",  \"Internet\",  \"Telecommunications\",  \"Consumer Services\",  \"Education Management\"\n",
    "    3. Employment_type:   \"Missing\",  \"Other\",  \"Full-time\",  \"Part-time\",  \"Contract\",  \"Temporary\" \n",
    "\n",
    "    Please always select \"Other\", when you are sure that the country, industry, or employment_type is mentioned within the job add but not one of the provided examples.\n",
    "    Never assume anything which is not written in the job offer. When you can not extract any value metnioned in the list and not select \"other\", always set the value to missing.\n",
    "\n",
    "    The output should be only three values in the order: Country, Industry, Emplyment_type\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "human_msg = \"Please search the following job description add and provide the the values for the three categories Country, Industry, Employment_type, without any other text.\"\n",
    "\n",
    "job_description = HumanMessage(human_msg + \"\\n\" + df['job_description'][id])\n",
    "\n",
    "messages = [system_msg, job_description]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2188f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(messages)\n",
    "\n",
    "# Display the response\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7233c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NZ', 'Marketing and Advertising', 'Full-time')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"country\"][id], df[\"industry\"][id], df[\"employment_type\"][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882cf489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scam_job_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
